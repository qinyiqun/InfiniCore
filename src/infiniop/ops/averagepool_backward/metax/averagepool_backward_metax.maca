#include "../../../devices/metax/metax_common.h"
#include "../../../devices/metax/metax_handle.h"
#include "averagepool_backward_metax.h"
#include "../cuda/averagepool_backward_kernel.cuh"
#include <cstdio>

// 自定义核函数
infiniStatus_t launch_avgpool_pytorch_backward_kernel(
    const op::averagepool_backward::AvgPoolBackwardInfo& info,
    const void* grad_output, void* grad_input,
    infiniDtype_t data_type, hcStream_t stream) {
    
    // 在累加梯度之前，必须将grad_input张量清零
    size_t grad_input_nelem = info.batch * info.channels;
    for (size_t i = 0; i < info.ndim; ++i) grad_input_nelem *= info.input_dims[i];

    size_t dtype_size = 0;
    switch (data_type) {
        case INFINI_DTYPE_F32:
            dtype_size = sizeof(float);
            break;
        case INFINI_DTYPE_F16:
            dtype_size = sizeof(half);
            break;
        case INFINI_DTYPE_BF16:
            dtype_size = sizeof(__hpcc_bfloat16);
            break;
        default:
            return INFINI_STATUS_NOT_IMPLEMENTED; // Or handle error
    }
    
    size_t grad_input_bytes = grad_input_nelem * dtype_size; 
    hcMemsetAsync(grad_input, 0, grad_input_bytes, stream);

    int batch_size = static_cast<int>(info.batch);
    int channels = static_cast<int>(info.channels);
    
    if (info.ndim == 1) {
        int input_length = static_cast<int>(info.input_dims[0]);
        int output_length = static_cast<int>(info.output_dims[0]);
        int kernel_size = static_cast<int>(info.kernel_sizes[0]);
        int stride = static_cast<int>(info.strides[0]);
        int padding = static_cast<int>(info.pads[0]);
        
        dim3 blockSize(256);
        dim3 gridSize(batch_size, channels, (output_length + blockSize.x - 1) / blockSize.x);
        
        switch (data_type) {
        case INFINI_DTYPE_F32:
            avgpool1d_pytorch_backward_kernel<float><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const float*>(grad_output), static_cast<float*>(grad_input),
                batch_size, channels, input_length, output_length,
                kernel_size, stride, padding);
            break;
        case INFINI_DTYPE_F16:
            avgpool1d_pytorch_backward_kernel<half><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const half*>(grad_output), static_cast<half*>(grad_input),
                batch_size, channels, input_length, output_length,
                kernel_size, stride, padding);
            break;
        case INFINI_DTYPE_BF16:
            avgpool1d_pytorch_backward_kernel<__hpcc_bfloat16><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const __hpcc_bfloat16*>(grad_output), static_cast<__hpcc_bfloat16*>(grad_input),
                batch_size, channels, input_length, output_length,
                kernel_size, stride, padding);
            break;
        default:
            return INFINI_STATUS_NOT_IMPLEMENTED;
        }
        
    } else if (info.ndim == 2) {
        // 2D平均池化 - 后向
        int input_height = static_cast<int>(info.input_dims[0]);
        int input_width = static_cast<int>(info.input_dims[1]);
        int output_height = static_cast<int>(info.output_dims[0]);
        int output_width = static_cast<int>(info.output_dims[1]);
        int kernel_h = static_cast<int>(info.kernel_sizes[0]);
        int kernel_w = static_cast<int>(info.kernel_sizes[1]);
        int stride_h = static_cast<int>(info.strides[0]);
        int stride_w = static_cast<int>(info.strides[1]);
        int pad_h = static_cast<int>(info.pads[0]);
        int pad_w = static_cast<int>(info.pads[1]);
        
        int total_output_elements = output_height * output_width;
        dim3 blockSize(256);
        dim3 gridSize(batch_size, channels, (total_output_elements + blockSize.x - 1) / blockSize.x);
        
        switch (data_type) {
        case INFINI_DTYPE_F32:
            avgpool2d_pytorch_backward_kernel<float><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const float*>(grad_output), static_cast<float*>(grad_input),
                batch_size, channels, input_height, input_width,
                output_height, output_width, kernel_h, kernel_w,
                stride_h, stride_w, pad_h, pad_w);
            break;
        case INFINI_DTYPE_F16:
            avgpool2d_pytorch_backward_kernel<half><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const half*>(grad_output), static_cast<half*>(grad_input),
                batch_size, channels, input_height, input_width,
                output_height, output_width, kernel_h, kernel_w,
                stride_h, stride_w, pad_h, pad_w);
            break;
        case INFINI_DTYPE_BF16:
            avgpool2d_pytorch_backward_kernel<__hpcc_bfloat16><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const __hpcc_bfloat16*>(grad_output), static_cast<__hpcc_bfloat16*>(grad_input),
                batch_size, channels, input_height, input_width,
                output_height, output_width, kernel_h, kernel_w,
                stride_h, stride_w, pad_h, pad_w);
            break;
        default:
            return INFINI_STATUS_NOT_IMPLEMENTED;
        }
        
    } else if (info.ndim == 3) {
        // 3D平均池化 - 后向
        int input_depth = static_cast<int>(info.input_dims[0]);
        int input_height = static_cast<int>(info.input_dims[1]);
        int input_width = static_cast<int>(info.input_dims[2]);
        int output_depth = static_cast<int>(info.output_dims[0]);
        int output_height = static_cast<int>(info.output_dims[1]);
        int output_width = static_cast<int>(info.output_dims[2]);
        int kernel_d = static_cast<int>(info.kernel_sizes[0]);
        int kernel_h = static_cast<int>(info.kernel_sizes[1]);
        int kernel_w = static_cast<int>(info.kernel_sizes[2]);
        int stride_d = static_cast<int>(info.strides[0]);
        int stride_h = static_cast<int>(info.strides[1]);
        int stride_w = static_cast<int>(info.strides[2]);
        int pad_d = static_cast<int>(info.pads[0]);
        int pad_h = static_cast<int>(info.pads[1]);
        int pad_w = static_cast<int>(info.pads[2]);
        
        int total_output_elements = output_depth * output_height * output_width;
        dim3 blockSize(256);
        dim3 gridSize(batch_size, channels, (total_output_elements + blockSize.x - 1) / blockSize.x);
        
        switch (data_type) {
        case INFINI_DTYPE_F32:
            avgpool3d_pytorch_backward_kernel<float><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const float*>(grad_output), static_cast<float*>(grad_input),
                batch_size, channels, input_depth, input_height, input_width,
                output_depth, output_height, output_width,
                kernel_d, kernel_h, kernel_w, stride_d, stride_h, stride_w,
                pad_d, pad_h, pad_w);
            break;
        case INFINI_DTYPE_F16:
            avgpool3d_pytorch_backward_kernel<half><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const half*>(grad_output), static_cast<half*>(grad_input),
                batch_size, channels, input_depth, input_height, input_width,
                output_depth, output_height, output_width,
                kernel_d, kernel_h, kernel_w, stride_d, stride_h, stride_w,
                pad_d, pad_h, pad_w);
            break;
        case INFINI_DTYPE_BF16:
            avgpool3d_pytorch_backward_kernel<__hpcc_bfloat16><<<gridSize, blockSize, 0, stream>>>(
                static_cast<const __hpcc_bfloat16*>(grad_output), static_cast<__hpcc_bfloat16*>(grad_input),
                batch_size, channels, input_depth, input_height, input_width,
                output_depth, output_height, output_width,
                kernel_d, kernel_h, kernel_w, stride_d, stride_h, stride_w,
                pad_d, pad_h, pad_w);
            break;
        default:
            return INFINI_STATUS_NOT_IMPLEMENTED;
        }
        
    } else {
        return INFINI_STATUS_BAD_PARAM;
    }
    
    return INFINI_STATUS_SUCCESS;
}

#define DESTROY_hcdnn_DESCRIPTOR(desc_ptr, destroy_func)                       \
  do {                                                                         \
    if (desc_ptr) {                                                            \
      destroy_func(desc_ptr);                                                  \
      desc_ptr = nullptr;                                                      \
    }                                                                          \
  } while (0)

#define CLEANUP_hcdnn_DESCRIPTORS()                                            \
  do {                                                                         \
    DESTROY_hcdnn_DESCRIPTOR(input_desc, hcdnnDestroyTensorDescriptor);        \
    DESTROY_hcdnn_DESCRIPTOR(grad_input_desc, hcdnnDestroyTensorDescriptor);   \
    DESTROY_hcdnn_DESCRIPTOR(grad_output_desc, hcdnnDestroyTensorDescriptor);  \
    DESTROY_hcdnn_DESCRIPTOR(pooling_backward_desc,                            \
                             hcdnnDestroyPoolingDescriptor);                   \
  } while (0)

namespace op::averagepool_backward::metax {

struct Descriptor::Opaque {
    std::shared_ptr<device::metax::Handle::Internal> internal;
    size_t workspace_size = 0;

#ifdef ENABLE_HCDNN_API
    hcdnnTensorDescriptor_t input_desc = nullptr;
    hcdnnTensorDescriptor_t grad_input_desc = nullptr;
    hcdnnTensorDescriptor_t grad_output_desc = nullptr;
    hcdnnPoolingDescriptor_t pooling_backward_desc = nullptr;
#endif

private:
    Opaque(std::shared_ptr<device::metax::Handle::Internal> internal_ptr)
      : internal(internal_ptr) {}

#ifdef ENABLE_HCDNN_API
    void calculateStrides(const std::vector<int> &dims, std::vector<int> &strides,
                        int ndim) const {
    strides[ndim - 1] = 1;
    for (int d = ndim - 2; d >= 0; --d) {
      strides[d] = strides[d + 1] * dims[d + 1];
    }
  }

  infiniStatus_t createPoolingDescriptors(const AvgPoolBackwardInfo &info,
                                         hcdnnDataType_t hcdnn_data_type) {
    // 创建hcdnn描述符
    CHECK_MCDNN(hcdnnCreateTensorDescriptor(&input_desc));
    CHECK_MCDNN(hcdnnCreateTensorDescriptor(&grad_input_desc));
    CHECK_MCDNN(hcdnnCreateTensorDescriptor(&grad_output_desc));
    CHECK_MCDNN(hcdnnCreatePoolingDescriptor(&pooling_backward_desc));

    // 构建输入、输出梯度维度（NCHW格式）
    std::vector<int> input_dims_vec = {static_cast<int>(info.batch),
                                       static_cast<int>(info.channels)};
    std::vector<int> output_dims_vec = {static_cast<int>(info.batch),
                                        static_cast<int>(info.channels)};
    for (size_t i = 0; i < info.ndim; ++i) {
      input_dims_vec.push_back(static_cast<int>(info.input_dims[i]));
      output_dims_vec.push_back(static_cast<int>(info.output_dims[i]));
    }

    while (input_dims_vec.size() < 5)  input_dims_vec.push_back(1);
    while (output_dims_vec.size() < 5) output_dims_vec.push_back(1);

    // 计算内存步幅
    std::vector<int> input_strides_vec(input_dims_vec.size());
    std::vector<int> output_strides_vec(output_dims_vec.size());
    calculateStrides(input_dims_vec, input_strides_vec, input_dims_vec.size());
    calculateStrides(output_dims_vec, output_strides_vec, output_dims_vec.size());

    // 设置张量描述符（带步幅）
    CHECK_MCDNN(hcdnnSetTensorNdDescriptor(
        input_desc, hcdnn_data_type, input_dims_vec.size(),
        input_dims_vec.data(), input_strides_vec.data()));

    CHECK_MCDNN(hcdnnSetTensorNdDescriptor(
        grad_input_desc, hcdnn_data_type, input_dims_vec.size(),
        input_dims_vec.data(), input_strides_vec.data()));

    CHECK_MCDNN(hcdnnSetTensorNdDescriptor(
        grad_output_desc, hcdnn_data_type, output_dims_vec.size(),
        output_dims_vec.data(), output_strides_vec.data()));

    return INFINI_STATUS_SUCCESS;
  }

  infiniStatus_t setupPoolingDescriptor(const AvgPoolBackwardInfo &info) {
    // 构建池化参数
    std::vector<int> kernel_vec, stride_vec, pad_vec;
    for (size_t i = 0; i < info.ndim; ++i) {
      kernel_vec.push_back(static_cast<int>(info.kernel_sizes[i]));
      stride_vec.push_back(static_cast<int>(info.strides[i]));
      pad_vec.push_back(static_cast<int>(info.pads[i]));
    }

    while (kernel_vec.size() < 3) kernel_vec.push_back(1);
    while (stride_vec.size() < 3) stride_vec.push_back(1);
    while (pad_vec.size() < 3)    pad_vec.push_back(0);

    // 设置平均池化反向描述符
    CHECK_MCDNN(hcdnnSetPoolingNdDescriptor(
        pooling_backward_desc, 
        HCDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING, // 平均池化模式
        HCDNN_NOT_PROPAGATE_NAN,                     // 不传播NaN
        kernel_vec.size(),
        kernel_vec.data(),
        pad_vec.data(),
        stride_vec.data()));

    return INFINI_STATUS_SUCCESS;
  }

  infiniStatus_t initializeHcdnnContext(AvgPoolBackwardInfo &info,
                                        infiniDtype_t data_type) {
    hcdnnDataType_t hcdnn_data_type = device::metax::getHcdnnDtype(data_type);

    CHECK_STATUS(createPoolingDescriptors(info, hcdnn_data_type));
    CHECK_STATUS(setupPoolingDescriptor(info));

    // 计算工作空间大小（需要存储前向输出用于反向计算）
    CHECK_MCDNN(hcdnnGetTensorSizeInBytes(grad_output_desc, &workspace_size));

    return INFINI_STATUS_SUCCESS;
  }
#endif

public:
    Opaque(Opaque &&other) noexcept
      : internal(std::move(other.internal)),
        workspace_size(other.workspace_size)
#ifdef ENABLE_HCDNN_API
        , input_desc(other.input_desc)
        , grad_input_desc(other.grad_input_desc)
        , grad_output_desc(other.grad_output_desc)
        , pooling_backward_desc(other.pooling_backward_desc)
#endif
    {
#ifdef ENABLE_HCDNN_API
        other.input_desc = nullptr;
        other.grad_input_desc = nullptr;
        other.grad_output_desc = nullptr;
        other.pooling_backward_desc = nullptr;
#endif
        other.workspace_size = 0;
    }

    ~Opaque() {
#ifdef ENABLE_HCDNN_API
        CLEANUP_hcdnn_DESCRIPTORS();
#endif
    }

    static inline utils::Result<Opaque>
    create(std::shared_ptr<device::metax::Handle::Internal> internal_ptr,
           AvgPoolBackwardInfo &info, infiniDtype_t data_type) {
#ifdef ENABLE_HCDNN_API
        Opaque opaque(internal_ptr);
        if (!info.has_implicit_padding) {
            auto status = opaque.initializeHcdnnContext(info, data_type);
            if (status != INFINI_STATUS_SUCCESS) {
                return status;
            }
        }
        return utils::Result<Opaque>(std::move(opaque));
#else
        return INFINI_STATUS_NOT_IMPLEMENTED;
#endif
    }
};

Descriptor::~Descriptor() {
    if (_opaque) {
        delete _opaque;
    }
}

infiniStatus_t Descriptor::create(infiniopHandle_t handle_,
                                  Descriptor **desc_ptr,
                                  infiniopTensorDescriptor_t grad_input_desc,
                                  infiniopTensorDescriptor_t grad_output_desc,
                                  infiniopTensorDescriptor_t input_desc,
                                  void *kernel_size, void *strides, void *pads,
                                  bool ceil_mode) {

#ifdef ENABLE_HCDNN_API
    auto handle = reinterpret_cast<device::metax::Handle *>(handle_);
    auto dtype = input_desc->dtype();
    auto result =
      AvgPoolBackwardInfo::create(grad_input_desc, grad_output_desc, input_desc,
                                  kernel_size, strides, pads, ceil_mode);
    CHECK_RESULT(result);
    auto info = result.take();

    auto opaque_result = Opaque::create(handle->internal(), info, dtype);
    CHECK_RESULT(opaque_result);
    auto opaque = new Opaque(opaque_result.take());

    *desc_ptr = new Descriptor(dtype, std::move(info), opaque->workspace_size,
                             opaque, handle->device, handle->device_id);

    return INFINI_STATUS_SUCCESS;
#else
    return INFINI_STATUS_NOT_IMPLEMENTED;
#endif
}

infiniStatus_t Descriptor::calculate(void *workspace, size_t workspace_size,
                                     void *grad_input, const void *grad_output,
                                     const void *input, void *stream) const {
#ifdef ENABLE_HCDNN_API
    if (_info.has_implicit_padding) {
        return launch_avgpool_pytorch_backward_kernel(
            _info, grad_output, grad_input, _dtype, (hcStream_t)stream);
    } else {
        const float alpha = 1.0f, beta = 0.0f;
        if (workspace_size < _workspace_size) {
            return INFINI_STATUS_INSUFFICIENT_WORKSPACE;
        }
        CHECK_STATUS(_opaque->internal->useMcdnn(
            (hcStream_t)stream, [&](hcdnnHandle_t handle) {
                void *temp_output = workspace;
                CHECK_MCDNN(hcdnnPoolingForward(
                    handle, _opaque->pooling_backward_desc, &alpha,
                    _opaque->input_desc, input, 
                    &beta, 
                    _opaque->grad_output_desc, temp_output));
                CHECK_MCDNN(hcdnnPoolingBackward(
                    handle, _opaque->pooling_backward_desc, &alpha,
                    _opaque->grad_output_desc, temp_output,
                    _opaque->grad_output_desc, grad_output,
                    _opaque->input_desc, input,
                    &beta,
                    _opaque->grad_input_desc, grad_input
                ));
                return INFINI_STATUS_SUCCESS;
            }));
        return INFINI_STATUS_SUCCESS;
    }
#else
    return INFINI_STATUS_NOT_IMPLEMENTED;
#endif
}

} // namespace op::averagepool_backward::metax
